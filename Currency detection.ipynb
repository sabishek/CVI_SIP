{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/env python\n",
    "# @Date:\t2017-03-22\n",
    "\n",
    "# UE14CS348 Digital Image Processing Mini Project\n",
    "# Indian paper currency detection\n",
    "\n",
    "# utils.py\n",
    "# contains utility functions\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# read image as is\n",
    "def read_img(file_name):\n",
    "\timg = cv2.imread(file_name)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "# resize image with fixed aspect ratio\n",
    "def resize_img(image, scale):\n",
    "\tres = cv2.resize(image, None, fx=scale, fy=scale, interpolation = cv2.INTER_AREA)\n",
    "\treturn res\n",
    "\n",
    "\n",
    "# convert image to grayscale\n",
    "def img_to_gray(image):\n",
    "\timg_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\treturn img_gray\n",
    "\n",
    "\n",
    "# gaussian blurred grayscale\n",
    "def img_to_gaussian_gray(image):\n",
    "\timg_gray = cv2.GaussianBlur(img_to_gray(image), (5, 5), 0)\n",
    "\treturn img_gray\n",
    "\n",
    "\n",
    "# convert image to negative\n",
    "def img_to_neg(image):\n",
    "\timg_neg = 255 - image\n",
    "\treturn img_neg\n",
    "\n",
    "\n",
    "# binarize (threshold)\n",
    "# retval not used currently\n",
    "def binary_thresh(image, threshold):\n",
    "\tretval, img_thresh = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
    "\treturn img_thresh\n",
    "\n",
    "\n",
    "# NO IDEA HOW THIS WPRKS\n",
    "def adaptive_thresh(image):\n",
    "\timg_thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 8)\n",
    "\t# cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) â†’ dsta\n",
    "\treturn img_thresh\n",
    "\n",
    "\n",
    "# sobel edge operator\n",
    "def sobel_edge(image, align):\n",
    "\timg_horiz = cv2.Sobel(image, cv2.CV_8U, 0, 1)\n",
    "\timg_vert = cv2.Sobel(image, cv2.CV_8U, 1, 0)\n",
    "\tif align == 'h':\n",
    "\t\treturn img_horiz\n",
    "\telif align == 'v':\n",
    "\t\treturn img_vert\n",
    "\telse:\n",
    "\t\tprint('use h or v')\n",
    "\n",
    "\n",
    "# sobel edge x + y\n",
    "def sobel_edge2(image):\n",
    "\t# ksize = size of extended sobel kernel\n",
    "\tgrad_x = cv2.Sobel(image, cv2.CV_16S, 1, 0, ksize=3, borderType = cv2.BORDER_DEFAULT)\n",
    "\tgrad_y = cv2.Sobel(image, cv2.CV_16S, 0, 1, ksize=3, borderType = cv2.BORDER_DEFAULT)\n",
    "\n",
    "\tabs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "\tabs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "\n",
    "\tdst = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "\treturn dst\n",
    "\n",
    "\n",
    "# canny edge operator\n",
    "def canny_edge(image, block_size, ksize):\n",
    "\t# block_size => Neighborhood size\n",
    "\t# ksize => Aperture parameter for the Sobel operator\n",
    "\t\n",
    "\t# 350, 350 => for smaller 500\n",
    "\t# 720, 350 => Devnagari 500, Reserve bank of India\n",
    "\t\n",
    "\timg = cv2.Canny(image, block_size, ksize)\n",
    "\t# dilate to fill up the numbers\n",
    "\t#img = cv2.dilate(img, None)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "# laplacian edge\n",
    "def laplacian_edge(image):\n",
    "\t# good for text\n",
    "\timg = cv2.Laplacian(image, cv2.CV_8U)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "# detect countours\n",
    "def find_contours(image):\n",
    "\t(_, contours, _) = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcontours = sorted(contours, key = cv2.contourArea, reverse = True)[:5]\n",
    "\treturn contours\n",
    "\n",
    "\n",
    "# median blur\n",
    "def median_blur(image):\n",
    "\tblurred_img = cv2.medianBlur(image, 3)\n",
    "\treturn blurred_img\n",
    "\n",
    "\n",
    "# dialte image to close lines\n",
    "def dilate_img(image):\n",
    "\timg = cv2.dilate(image, np.ones((5,5), np.uint8))\n",
    "\treturn img\n",
    "\n",
    "\n",
    "# erode image\n",
    "def close(image):\n",
    "\timg = cv2.Canny(image, 75, 300)\n",
    "\timg = cv2.dilate(img, None)\n",
    "\timg = cv2.erode(img, None)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def harris_edge(image):\n",
    "\timg_gray = np.float32(image)\n",
    "\n",
    "\tcorners = cv2.goodFeaturesToTrack(img_gray, 4, 0.03, 200, None, None, 2,useHarrisDetector=True, k=0.04)\n",
    "\tcorners = np.int0(corners)\n",
    "\n",
    "\tfor corner in corners:\n",
    "\t\tx, y = corner.ravel()\n",
    "\t\tcv2.circle(image, (x, y), 3, 255, -1)\n",
    "\treturn image\n",
    "\n",
    "\n",
    "# calculate histogram\n",
    "def histogram(image):\n",
    "\thist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "\t# cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]]) \n",
    "\tplt.plot(hist)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "# fast fourier transform\n",
    "def fourier(image):\n",
    "\tf = np.fft.fft2(image)\n",
    "\tfshift = np.fft.fftshift(f)\n",
    "\tmagnitude_spectrum = 20 * np.log(np.abs(fshift))\n",
    "\n",
    "\tplt.subplot(121), plt.imshow(image, cmap='gray')\n",
    "\tplt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "\tplt.subplot(122), plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "\tplt.title('FFT'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "# calculate scale and fit into display\n",
    "def display(window_name, image):\n",
    "\tscreen_res = 1440, 900\t# MacBook Air\n",
    "\t\n",
    "\tscale_width = screen_res[0] / image.shape[1]\n",
    "\tscale_height = screen_res[1] / image.shape[0]\n",
    "\tscale = min(scale_width, scale_height)\n",
    "\twindow_width = int(image.shape[1] * scale)\n",
    "\twindow_height = int(image.shape[0] * scale)\n",
    "\n",
    "\t# reescale the resolution of the window\n",
    "\tcv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\tcv2.resizeWindow(window_name, window_width, window_height)\n",
    "\n",
    "\t# display image\n",
    "\tcv2.imshow(window_name, image)\n",
    "\n",
    "\t# wait for any key to quit the program\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# test file\n",
    "# TODO:\n",
    "# \tFigure out four point transform\n",
    "#\tFigure out testing data warping\n",
    "# \tUse webcam as input\n",
    "# \tFigure out how to use contours\n",
    "# \t\tCurrently detects inner rect -> detect outermost rectangle\n",
    "# \tTry using video stream from android phone\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import subprocess\n",
    "#from gtts import gTTS\n",
    "\n",
    "\n",
    "max_val = 8\n",
    "max_pt = -1\n",
    "max_kp = 0\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "# orb is an alternative to SIFT\n",
    "\n",
    "#test_img = read_img('files/test_100_2.jpg')\n",
    "#test_img = read_img('files/test_50_2.jpg')\n",
    "test_img = read_img('files/test_20_2.jpg')\n",
    "#test_img = read_img('files/test_100_3.jpg')\n",
    "#test_img = read_img('files/test_20_4.jpg')\n",
    "\n",
    "# resizing must be dynamic\n",
    "original = resize_img(test_img, 0.4)\n",
    "display('original', original)\n",
    "\n",
    "# keypoints and descriptors\n",
    "# (kp1, des1) = orb.detectAndCompute(test_img, None)\n",
    "(kp1, des1) = orb.detectAndCompute(test_img, None)\n",
    "\n",
    "training_set = ['files/20.jpg', 'files/50.jpg', 'files/100.jpg', 'files/500.jpg']\n",
    "\n",
    "for i in range(0, len(training_set)):\n",
    "\t# train image\n",
    "\ttrain_img = cv2.imread(training_set[i])\n",
    "\n",
    "\t(kp2, des2) = orb.detectAndCompute(train_img, None)\n",
    "\n",
    "\t# brute force matcher\n",
    "\tbf = cv2.BFMatcher()\n",
    "\tall_matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "\tgood = []\n",
    "\t# give an arbitrary number -> 0.789\n",
    "\t# if good -> append to list of good matches\n",
    "\tfor (m, n) in all_matches:\n",
    "\t\tif m.distance < 0.789 * n.distance:\n",
    "\t\t\tgood.append([m])\n",
    "\n",
    "\tif len(good) > max_val:\n",
    "\t\tmax_val = len(good)\n",
    "\t\tmax_pt = i\n",
    "\t\tmax_kp = kp2\n",
    "\n",
    "\tprint(i, ' ', training_set[i], ' ', len(good))\n",
    "\n",
    "if max_val != 8:\n",
    "\tprint(training_set[max_pt])\n",
    "\tprint('good matches ', max_val)\n",
    "\n",
    "\ttrain_img = cv2.imread(training_set[max_pt])\n",
    "\timg3 = cv2.drawMatchesKnn(test_img, kp1, train_img, max_kp, good, 4)\n",
    "\t\n",
    "\tnote = str(training_set[max_pt])[6:-4]\n",
    "\tprint('\\nDetected denomination: Rs. ', note)\n",
    "\n",
    "\t#audio_file = 'audio/' + note + '.mp3'\n",
    "\n",
    "\t# audio_file = \"value.mp3\n",
    "\t# tts = gTTS(text=speech_out, lang=\"en\")\n",
    "\t# tts.save(audio_file)\n",
    "\treturn_code = subprocess.call([\"afplay\", audio_file])\n",
    "\n",
    "\t(plt.imshow(img3), plt.show())\n",
    "else:\n",
    "\tprint('No Matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
